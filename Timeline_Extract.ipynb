{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "192cmPcfnZrHUWJD1NbP29kq6z4DGnC8R",
      "authorship_tag": "ABX9TyOF/7hRf4nr+SRtlsHxQZ3L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NickJTutt/GoogleTimeline/blob/main/Timeline_Extract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Timeline Extract**\n",
        "\n",
        "Complete Google Timeline Extract and get \"Semantic History\".\n",
        "\n",
        "Place all months required to extract in single folder."
      ],
      "metadata": {
        "id": "uXaA7a-PLnuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function Definition\n",
        "import json\n",
        "import csv\n",
        "import math\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "\n",
        "def extract_location_data(file_path):\n",
        "    data = {}\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    location_data = []\n",
        "\n",
        "    for timelineObject in data['timelineObjects']:\n",
        "       # print('timelineObjects')\n",
        "        # Check if the timelineObject is a 'placeVisit'\n",
        "        if 'placeVisit' in timelineObject:\n",
        "            place_visit = timelineObject['placeVisit']\n",
        "           # print('placeVisit')\n",
        "            # Extracting the details\n",
        "            location = place_visit['location']\n",
        "            duration = place_visit['duration']\n",
        "\n",
        "            # Converting latitude and longitude to standard format\n",
        "            latitude = location['latitudeE7'] / 1e7\n",
        "          #  print(latitude)\n",
        "            longitude = location['longitudeE7'] / 1e7\n",
        "         #   print(longitude)\n",
        "\n",
        "            # Extracting start and end timestamps\n",
        "            start_timestamp = duration['startTimestamp']\n",
        "            end_timestamp = duration['endTimestamp']\n",
        "\n",
        "            # Extracting address\n",
        "            if 'address' in location:\n",
        "              address = location['address']\n",
        "            else:\n",
        "              address = 0\n",
        "\n",
        "            location_data.append({\n",
        "            'latitude': latitude,\n",
        "            'longitude': longitude,\n",
        "            'startTimestamp': start_timestamp,\n",
        "            'endTimestamp': end_timestamp,\n",
        "            'address': address\n",
        "            })\n",
        "        #print(location_data)\n",
        "\n",
        "    # Convert each dictionary in location_data to a tuple and add it to a set\n",
        "    # This will automatically remove any duplicates because sets only allow unique values\n",
        "    location_set = set(tuple(location.items()) for location in location_data)\n",
        "\n",
        "    # Convert the set back to a list of dictionaries\n",
        "    unique_location_data = [dict(location) for location in location_set]\n",
        "    sorted_location_data = sorted(unique_location_data, key=lambda x: x['startTimestamp'])\n",
        "    for i in range(1, len(sorted_location_data)):\n",
        "        sorted_location_data[i]['distance'] = calculate_distance(\n",
        "            sorted_location_data[i-1]['latitude'], sorted_location_data[i-1]['longitude'],\n",
        "            sorted_location_data[i]['latitude'], sorted_location_data[i]['longitude']\n",
        "        )\n",
        "    sorted_location_data[0]['distance'] = 0  # for the first location\n",
        "    adjusted_location_data = adjust_timestamps(sorted_location_data)\n",
        "    return adjusted_location_data\n",
        "\n",
        "def write_to_csv(location_data, csv_file_path):\n",
        "    # Define the CSV column headers\n",
        "    fieldnames = ['latitude', 'longitude', 'startTimestamp', 'endTimestamp', 'address', 'distance']\n",
        "\n",
        "    # Write the data to a CSV file\n",
        "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        writer.writeheader()\n",
        "        for row in location_data:\n",
        "            writer.writerow(row)\n",
        "\n",
        "\n",
        "def calculate_distance(lat1, lon1, lat2, lon2):\n",
        "    # Radius of the Earth in km\n",
        "    R = 6371.0\n",
        "\n",
        "    # Convert degrees to radians\n",
        "    lat1_rad = math.radians(lat1)\n",
        "    lon1_rad = math.radians(lon1)\n",
        "    lat2_rad = math.radians(lat2)\n",
        "    lon2_rad = math.radians(lon2)\n",
        "\n",
        "    # Differences\n",
        "    dlon = lon2_rad - lon1_rad\n",
        "    dlat = lat2_rad - lat1_rad\n",
        "\n",
        "    # Haversine formula\n",
        "    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2\n",
        "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
        "\n",
        "    # Distance\n",
        "    distance = R * c\n",
        "    return distance\n",
        "\n",
        "def reformat_timestamp(timestamp):\n",
        "    if '.' in timestamp:\n",
        "        # Format with milliseconds\n",
        "        dt_format = '%Y-%m-%dT%H:%M:%S.%fZ'\n",
        "    else:\n",
        "        # Format without milliseconds\n",
        "        dt_format = '%Y-%m-%dT%H:%M:%SZ'\n",
        "\n",
        "    # Parse the timestamp\n",
        "    dt = datetime.strptime(timestamp, dt_format)\n",
        "\n",
        "    # Add two hours\n",
        "    dt += timedelta(hours=2)\n",
        "\n",
        "    # Reformat the timestamp\n",
        "    return dt.strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "def adjust_timestamps(location_data):\n",
        "    for location in location_data:\n",
        "        location['startTimestamp'] = reformat_timestamp(location['startTimestamp'])\n",
        "        location['endTimestamp'] = reformat_timestamp(location['endTimestamp'])\n",
        "    return location_data\n",
        "\n",
        "def extract_data_from_multiple_files(directory):\n",
        "    # Get a list of all files in the directory\n",
        "    files = os.listdir(directory)\n",
        "\n",
        "    # Initialize an empty list to store all location data\n",
        "    all_location_data = []\n",
        "\n",
        "    # Iterate over each file\n",
        "    for file_name in files:\n",
        "      #print(file_name)\n",
        "    # Check if the file has a .json extension\n",
        "      if file_name.lower().endswith(\".json\"):\n",
        "          file_path = directory+'/'+file_name\n",
        "          # Extract location data from the file\n",
        "          location_data = extract_location_data(file_path)\n",
        "          #print(len(location_data))\n",
        "          # Add the location data to the main list\n",
        "          all_location_data.extend(location_data)\n",
        "\n",
        "\n",
        "    return all_location_data"
      ],
      "metadata": {
        "id": "JXNzQNTuClsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage\n",
        "directory = '/content/drive/MyDrive/2023' # location of .JSON files from google timeline semantic\n",
        "all_location_data = extract_data_from_multiple_files(directory)\n",
        "#Write to CSV\n",
        "csv_file_path = '/content/location_data.csv' #Where you want to save the csv output\n",
        "write_to_csv(all_location_data, csv_file_path)\n",
        "print('Saved to '+ csv_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYAjU43OvNKy",
        "outputId": "c53cea29-4c07-4e46-c244-bed66f50f67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to /content/location_data.csv\n"
          ]
        }
      ]
    }
  ]
}